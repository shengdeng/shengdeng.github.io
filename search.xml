<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[Spark与MapReduce对比测评]]></title>
      <url>http://shengdeng.github.io/2016/05/13/Spark%E4%B8%8EMapReduce%E5%AF%B9%E6%AF%94%E6%B5%8B%E8%AF%84/</url>
      <content type="html"><![CDATA[<h1 id="基本原理方面"><a href="#基本原理方面" class="headerlink" title="基本原理方面"></a>基本原理方面</h1><p>MapReduce:</p>
<ul>
<li>基于磁盘的大数据批量处理系统</li>
<li>Map和Reduce阶段都是往磁盘读写</li>
</ul>
<p>Spark</p>
<ul>
<li>基于RDD(弹性分布式数据集)数据处理。RDD可以显示地(即可指定)存储到磁盘和内存中</li>
</ul>
<p><strong>总结</strong>：Spark比MR更灵活，更快速</p>
<h1 id="模型方面"><a href="#模型方面" class="headerlink" title="模型方面"></a>模型方面</h1><p>MapReduce:</p>
<ul>
<li>可以处理超大规模的数据</li>
<li>适合日志分析挖掘等</li>
<li>较少的迭代的长任务需求</li>
<li>结合了数据的分布式计算、存储</li>
</ul>
<p>Spark</p>
<ul>
<li>适合海量数据，但不适合太大(毕竟数据放在内存中)</li>
<li>适合数据挖掘(迭代中间结果放在内存中，迭代时很快)、机器学习等多轮迭代式计算任务</li>
<li>在处理上是分布式的，但在存储上数据来源于HDFS等第三方系统</li>
</ul>
<p><strong>总结</strong>：Spark在数据挖掘处理方面比MapReduce优越，但在大规模数据处理上，目前MR更适合。</p>
<h1 id="容错性方面"><a href="#容错性方面" class="headerlink" title="容错性方面"></a>容错性方面</h1><p>数据的容错性、节点的容错性<br>MapReduce:</p>
<ul>
<li>数据的读和写都是往HDFS上，HDFS有很强的数据容错的措施</li>
</ul>
<p>Spark</p>
<ul>
<li>容错性建立在RDD的Linage上，重新构造RDD</li>
</ul>
<p><strong>总结</strong>：Spark在容错性方面并不比MapReduce优越</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[前沿技术追踪：伯克利数据分析堆栈]]></title>
      <url>http://shengdeng.github.io/2016/05/12/%E5%89%8D%E6%B2%BF%E6%8A%80%E6%9C%AF%E8%BF%BD%E8%B8%AA%EF%BC%9A%E4%BC%AF%E5%85%8B%E5%88%A9%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%A0%86%E6%A0%88/</url>
      <content type="html"><![CDATA[<p>伯克利数据分析堆栈(BDAS, the Berkeley Data Analytics Stack)是由AMPLab实验室提供的，以Spark Core计算引擎为核心的，一套完整应对各种大数据处理场的Spark生态系统。伯克利数据分析堆栈也会随着开源软件的发展不断向前演变。 <a href="https://amplab.cs.berkeley.edu/projects" target="_blank" rel="external">AMPLab实验室</a>作为推动Spark生态向前发展的主要力量，其提供的伯克利数据分析堆栈非常值得技术人员持续关注。【草稿版。。。】<br><a id="more"></a></p>
<h1 id="Spark历史回顾"><a href="#Spark历史回顾" class="headerlink" title="Spark历史回顾"></a>Spark历史回顾</h1><p><strong>2009年</strong>Spark作为一个研究项目在加州大学伯克利分校(UC Berkeley)的RAD实验室(AMPlab的前身)诞生。当时Spark的设计是为了弥补Hadoop MR在迭代计算、交互计算、计算时间方面效率底下的缺陷，因此Spark天生具备以下特性</p>
<ul>
<li>可交互式查询</li>
<li>迭代计算</li>
<li>内存式存储</li>
<li>高效容错</li>
</ul>
<p><strong>2010年3月</strong>Spark项目开源。</p>
<p><strong>2011年</strong>，AMPLab开始基于Spark开发更高层的组件，比如Spark Streaming。有AMP开发的这些基于Spark Core组件和其他组件一起被称为<a href="https://amplab.cs.berkeley.edu/software/" target="_blank" rel="external">伯克利数据分析堆栈</a>。分析栈随着技术的发展不断扩张和演变。</p>
<p><strong>2013年6月</strong>，Spark项目正式交给Apache基金会，目前已成为顶级项目。从此，Spark飞速发张。</p>
<h1 id="伯克利数据分析堆栈"><a href="#伯克利数据分析堆栈" class="headerlink" title="伯克利数据分析堆栈"></a>伯克利数据分析堆栈</h1><p>BDAS的所有组件如下图(2016年版，如<a href="https://amplab.cs.berkeley.edu/software/" target="_blank" rel="external">官网</a>有更新欢迎留言告诉我)。其中，蓝色和绿色的模块所代表的组件完全开源可用，点击链接可进入对应项目的主页下载或了解更多。<br><img src="http://7xtorv.com2.z0.glb.clouddn.com/%E6%8D%95%E8%8E%B7.PNG" alt=""></p>
<p><strong>BDAS主要包括三层：存储层、资源管理层和数据处理层</strong>。AMP自己的项目中除了处理层的Spark,还有管理层的Mesos，存储层的Tachyon；考虑到Hadoop生态圈技术在某些情况下数据处理的会更好，作为Spark的互补技术，Spark对Hadoop支持且能够和Hadoop整合在一起。因此，BDAS表示的Spark生态系统还包括Hadoop的技术。下面详谈各个模块的细节。</p>
<h2 id="存储层"><a href="#存储层" class="headerlink" title="存储层"></a>存储层</h2><h2 id="资源管理层"><a href="#资源管理层" class="headerlink" title="资源管理层"></a>资源管理层</h2><p>Mesos是资源管理层的，使多框架可以分享同一个集群的资源。这里你只要有一个集群就可以了，而不需要有很多个，能够在多个框架上用。好处是什么？资源节省效率更高，并且更容易共享数据。</p>
<h2 id="处理层"><a href="#处理层" class="headerlink" title="处理层"></a>处理层</h2><p>Spark core是执行引擎，它有两个特点，它可以容错，内存存储效率也很高。在时效节点上它可以对数据进行重构，并且它有更强大的模型，也更快，比Hadoop MapReduce快上100倍。对于同样一个应用来说它写的代码量要比Hadoop MapReduce少2到5倍，并且它也支持互动计算。也就是说它对内存的利用效率更高，能更快得到响应，并且也可以通过内存共享数据。在Spark Core上面有很多个框架：</p>
<h3 id="Spark-Streaming"><a href="#Spark-Streaming" class="headerlink" title="Spark Streaming"></a>Spark Streaming</h3><p>用Spark的功能做快速的计算。流式计算更适用于实时计算的场景。我们可以用它处理不同节点的计算，所有的这些特性实际上在其他类似Spark Streaming技术上不能实现的。这里我们支持批量流的计算。</p>
<h3 id="MLlib"><a href="#MLlib" class="headerlink" title="MLlib"></a>MLlib</h3><p>用于机器学习的高质量库</p>
<h3 id="Graphx"><a href="#Graphx" class="headerlink" title="Graphx"></a>Graphx</h3><p>这个Graphx可以整合数据和图并行计算，就是对数据的平行计算以及表格的平行计算进行整合，提供了非常高的抽象等级。同时，它还借鉴了Apache Spark的纠错功能。</p>
<h3 id="BlinkDB"><a href="#BlinkDB" class="headerlink" title="BlinkDB"></a>BlinkDB</h3><p>使用抽样方法在<strong>性能</strong>和<strong>准确性</strong>之间做平衡，服务器响应速度非常快。用Sql查询，BlinkDB可以在一定的响应时间内进行查询，目前仍在开发过程中，将来是Spark的一个非常重要的部分。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Spark四大特性]]></title>
      <url>http://shengdeng.github.io/2016/05/10/Spark%E5%9B%9B%E5%A4%A7%E7%89%B9%E6%80%A7/</url>
      <content type="html"><![CDATA[<p><a href="http://spark.apache.org/" target="_blank" rel="external">Apache Spark™</a> is a fast and general engine for large-scale data processing.<br>Apache Spark™是一个<strong>快速的</strong>、<strong>通用的</strong>，针对于<strong>大数据集</strong>的<strong>数据处理分析</strong>的计算引擎（框架）。</p>
<ul>
<li>Hadoop:数据存储（HDFS）与分析(MR)</li>
<li>Spark：数据分析</li>
</ul>
<p>在数据处理上Spark与MR比较，主要有如下四点优势特性</p>
<a id="more"></a>
<h1 id="快速-Speed"><a href="#快速-Speed" class="headerlink" title="快速(Speed)"></a>快速(Speed)</h1><p>与Hadoop MapReduce比较，内存中运行快100倍以上，磁盘中运行快10倍以上。</p>
<p>主要原因：</p>
<ol>
<li>Spark使用有向无环图DAG（任务划为一个一个流程图）</li>
<li>Spark在内存中运行（MR map输出结果仿真磁盘，reduce读数据从磁盘读，磁盘读写速度依赖网络IO、磁盘速度）</li>
</ol>
<h1 id="易使用-Ease-of-Use"><a href="#易使用-Ease-of-Use" class="headerlink" title="易使用(Ease of Use)"></a>易使用(Ease of Use)</h1><p>spark编程简单，支持scala、java、python，尤其scala和python代码很简洁，代码量少：</p>
<ul>
<li>spark提供了<strong>80个以上的操作</strong>（除了map\reduce还有很多操作）使得编程简单。</li>
<li>提供了可交互的 <strong>scala shell</strong> 和 python shell</li>
</ul>
<p>MR编程则十分麻烦，虽然有模板可以套用，但代码总体庞大；MR只有map和reduce两个操作，一个业务总要想办法拆成（多个）map和reduce，甚至多个job，</p>
<h1 id="通用性-Generality"><a href="#通用性-Generality" class="headerlink" title="通用性(Generality)"></a>通用性(Generality)</h1><p>Spark框架可以视为core，建立在spark运算框架上，还有其他专用框架（像MR上建立的框架：MapReduce难写有了Hive框架、机器学习Mahont框架、Pig、图形计算Giraph），Spark上的框架相当于一些Jar包库，不需要像Hive、Mahont要另外部署配置。</p>
<p>Spark powers（为…提供动力） a stack of libraries including SQL and DataFrames, MLlib for machine learning, GraphX, and Spark Streaming. You can combine these libraries seamlessly in the same application.<br>Spark内核框架驱动一堆高级工具库包括SQL，DataFrames, 机器学习库MLlib, GraphX, and Spark Streaming。 你只要部署好了spark，这些类库就直接可以用，即<strong>一站式的大数据处理解决方案(One stack to rule all!)</strong>。因此不需要为了各种业务而搭建平台。（Hadoop平台上要为了各种业务搭建一堆东西，比如Hive、Pig等等）</p>
<p>总之，基于Spark core上的大一统软件栈的优点：</p>
<ul>
<li>spark下层core的改进优化时，上层程序库也自动获得性能提升；</li>
<li>运行整个软件栈的代价小（包括部署、维护、测试、支持），不需要运行多套独立的软件系统；</li>
<li>能够无缝整合不同处理模型的应用（如机器学习的应用和SQL实时查询结果数据的应用在Spark上同时进行）</li>
</ul>
<h1 id="运行在各个地方-Runs-Everywhere"><a href="#运行在各个地方-Runs-Everywhere" class="headerlink" title="运行在各个地方(Runs Everywhere)"></a>运行在各个地方(Runs Everywhere)</h1><p>多种运行方式</p>
<ul>
<li>单独部署：standalone</li>
<li>Yarn</li>
<li>类似于yarn的资源管理框架Mesos</li>
<li>云端：EMC、EC2</li>
</ul>
<p>运行数据来源</p>
<ul>
<li><strong>Spark可以支持任何实现了Hadoop API的存储系统</strong>(Access data in HDFS, Cassandra, HBase, Hive, Tachyon, and any Hadoop data source.)。Spark可以从存储在Hadoop分布式文件系统（HDFS）中的任何文件，或其他Hadoop API支持的存储系统（如本地文件系统，Amazon S3， Cassandra， Hive，HBase等）创建分布式数据集。</li>
<li><strong>Hadoop对Spark来说不是必须的</strong>，Spark支持文本文件、序列文件、Avro、Parquet，以及任何其他Hadoop的输入格式。</li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Kafka官方文档中文版：第1章 Getting Started]]></title>
      <url>http://shengdeng.github.io/2016/05/06/Kafka%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E4%B8%AD%E6%96%87%E7%89%88%EF%BC%9A%E7%AC%AC1%E7%AB%A0GettingStarted/</url>
      <content type="html"><![CDATA[<p><a href="http://kafka.apache.org/documentation.html" target="_blank" rel="external">Kafka版本：0.9.0</a></p>
<p>正在持续更新中…</p>
<a id="more"></a>
<h1 id="1-1-引言-Introduction"><a href="#1-1-引言-Introduction" class="headerlink" title="1.1 引言(Introduction)"></a>1.1 引言(Introduction)</h1><p>Kafka is a distributed, partitioned, replicated commit log service. It provides the functionality of a messaging system, but with a unique design.<br>What does all that mean?</p>
<p>First let’s review some basic messaging terminology:</p>
<ul>
<li>Kafka maintains feeds of messages in categories called topics.</li>
<li>We’ll call processes that publish messages to a Kafka topic producers.</li>
<li>We’ll call processes that subscribe to topics and process the feed of published messages consumers..</li>
<li>Kafka is run as a cluster comprised of one or more servers each of which is called a broker.</li>
</ul>
<p>So, at a high level, producers send messages over the network to the Kafka cluster which in turn serves them up to consumers like this:</p>
<h2 id="Topics-and-Logs"><a href="#Topics-and-Logs" class="headerlink" title="Topics and Logs"></a>Topics and Logs</h2><p>Let’s first dive into the high-level abstraction Kafka provides—the topic.<br>A topic is a category or feed name to which messages are published. For each topic, the Kafka cluster maintains a partitioned log that looks like this:</p>
<p>Each partition is an ordered, immutable sequence of messages that is continually appended to—a commit log. The messages in the partitions are each assigned a sequential id number called the offset that uniquely identifies each message within the partition.<br>The Kafka cluster retains all published messages—whether or not they have been consumed—for a configurable period of time. For example if the log retention is set to two days, then for the two days after a message is published it is available for consumption, after which it will be discarded to free up space. Kafka’s performance is effectively constant with respect to data size so retaining lots of data is not a problem.</p>
<p>In fact the only metadata retained on a per-consumer basis is the position of the consumer in the log, called the “offset”. This offset is controlled by the consumer: normally a consumer will advance its offset linearly as it reads messages, but in fact the position is controlled by the consumer and it can consume messages in any order it likes. For example a consumer can reset to an older offset to reprocess.</p>
<p>This combination of features means that Kafka consumers are very cheap—they can come and go without much impact on the cluster or on other consumers. For example, you can use our command line tools to “tail” the contents of any topic without changing what is consumed by any existing consumers.</p>
<p>The partitions in the log serve several purposes. First, they allow the log to scale beyond a size that will fit on a single server. Each individual partition must fit on the servers that host it, but a topic may have many partitions so it can handle an arbitrary amount of data. Second they act as the unit of parallelism—more on that in a bit.</p>
<h2 id="Distribution"><a href="#Distribution" class="headerlink" title="Distribution"></a>Distribution</h2><p>The partitions of the log are distributed over the servers in the Kafka cluster with each server handling data and requests for a share of the partitions. Each partition is replicated across a configurable number of servers for fault tolerance.<br>Each partition has one server which acts as the “leader” and zero or more servers which act as “followers”. The leader handles all read and write requests for the partition while the followers passively replicate the leader. If the leader fails, one of the followers will automatically become the new leader. Each server acts as a leader for some of its partitions and a follower for others so load is well balanced within the cluster.</p>
<h2 id="Producers"><a href="#Producers" class="headerlink" title="Producers"></a>Producers</h2><p>Producers publish data to the topics of their choice. The producer is responsible for choosing which message to assign to which partition within the topic. This can be done in a round-robin fashion simply to balance load or it can be done according to some semantic partition function (say based on some key in the message). More on the use of partitioning in a second.<br>Consumers</p>
<p>Messaging traditionally has two models: queuing and publish-subscribe. In a queue, a pool of consumers may read from a server and each message goes to one of them; in publish-subscribe the message is broadcast to all consumers. Kafka offers a single consumer abstraction that generalizes both of these—the consumer group.<br>Consumers label themselves with a consumer group name, and each message published to a topic is delivered to one consumer instance within each subscribing consumer group. Consumer instances can be in separate processes or on separate machines.</p>
<p>If all the consumer instances have the same consumer group, then this works just like a traditional queue balancing load over the consumers.</p>
<p>If all the consumer instances have different consumer groups, then this works like publish-subscribe and all messages are broadcast to all consumers.</p>
<p>More commonly, however, we have found that topics have a small number of consumer groups, one for each “logical subscriber”. Each group is composed of many consumer instances for scalability and fault tolerance. This is nothing more than publish-subscribe semantics where the subscriber is cluster of consumers instead of a single process.</p>
<p>A two server Kafka cluster hosting four partitions (P0-P3) with two consumer groups. Consumer group A has two consumer instances and group B has four.<br>Kafka has stronger ordering guarantees than a traditional messaging system, too.</p>
<p>A traditional queue retains messages in-order on the server, and if multiple consumers consume from the queue then the server hands out messages in the order they are stored. However, although the server hands out messages in order, the messages are delivered asynchronously to consumers, so they may arrive out of order on different consumers. This effectively means the ordering of the messages is lost in the presence of parallel consumption. Messaging systems often work around this by having a notion of “exclusive consumer” that allows only one process to consume from a queue, but of course this means that there is no parallelism in processing.</p>
<p>Kafka does it better. By having a notion of parallelism—the partition—within the topics, Kafka is able to provide both ordering guarantees and load balancing over a pool of consumer processes. This is achieved by assigning the partitions in the topic to the consumers in the consumer group so that each partition is consumed by exactly one consumer in the group. By doing this we ensure that the consumer is the only reader of that partition and consumes the data in order. Since there are many partitions this still balances the load over many consumer instances. Note however that there cannot be more consumer instances in a consumer group than partitions.</p>
<p>Kafka only provides a total order over messages within a partition, not between different partitions in a topic. Per-partition ordering combined with the ability to partition data by key is sufficient for most applications. However, if you require a total order over messages this can be achieved with a topic that has only one partition, though this will mean only one consumer process per consumer group.</p>
<h2 id="Guarantees"><a href="#Guarantees" class="headerlink" title="Guarantees"></a>Guarantees</h2><p>At a high-level Kafka gives the following guarantees:<br>Messages sent by a producer to a particular topic partition will be appended in the order they are sent. That is, if a message M1 is sent by the same producer as a message M2, and M1 is sent first, then M1 will have a lower offset than M2 and appear earlier in the log.<br>A consumer instance sees messages in the order they are stored in the log.<br>For a topic with replication factor N, we will tolerate up to N-1 server failures without losing any messages committed to the log.<br>More details on these guarantees are given in the design section of the documentation</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Spark编程指南中文版]]></title>
      <url>http://shengdeng.github.io/2016/05/06/Spark%E7%BC%96%E7%A8%8B%E6%8C%87%E5%8D%97%E4%B8%AD%E6%96%87%E7%89%88/</url>
      <content type="html"><![CDATA[<p><a href="http://spark.apache.org/docs/latest/programming-guide.html" target="_blank" rel="external">Spark版本：1.6.1</a></p>
<p>正在持续更新中…</p>
<a id="more"></a>
<h1 id="1-概述-Overview"><a href="#1-概述-Overview" class="headerlink" title="1 概述(Overview)"></a>1 概述(Overview)</h1><p>总体来讲，每一个Spark驱动程序应用都由一个驱动程序组成，该驱动程序包含一个由用户编写的main方法，该方法会在集群上并行执行一些列并行计算操作。Spark最重要的一个概念是弹性分布式数据集，简称RDD（resilient distributed dataset ）。RDD是一个数据容器，它将分布在集群上各个节点上的数据抽象为一个数据集，并且RDD能够进行一系列的并行计算操作。可以将RDD理解为一个分布式的List，该List的数据为分布在各个节点上的数据。RDD通过读取Hadoop文件系统中的一个文件进行创建，也可以由一个RDD经过转换得到。用户也可以将RDD缓存至内存，从而高效的处理RDD，提高计算效率。另外，RDD有良好的容错机制。</p>
<p>Spark另外一个重要的概念是共享变量（shared variables）。在并行计算时，可以方便的使用共享变量。在默认情况下，执行Spark任务时会在多个节点上并行执行多个task，Spark将每个变量的副本分发给各个task。在一些场景下，需要一个能够在各个task间共享的变量。Spark支持两种类型的共享变量：</p>
<ul>
<li><p>广播变量（broadcast variables）：将一个只读变量缓存到集群的每个节点上。例如，将一份数据的只读缓存分发到每个节点。</p>
</li>
<li><p>累加变量（accumulators）：只允许add操作，用于计数、求和。</p>
</li>
</ul>
<h1 id="2-引入Spark（Linking-with-Spark"><a href="#2-引入Spark（Linking-with-Spark" class="headerlink" title="2 引入Spark（Linking with Spark)"></a>2 引入Spark（Linking with Spark)</h1><p>在Spark 1.6.0上编写应用程序，支持使用Scala 2.10.X、Java 7+、Python 2.6+、R 3.1+。如果使用Java 8，支持lambda表达式（lambda expressions）。</p>
<p>在编写Spark应用时，需要在Maven依赖中添加Spark，Spark的Maven Central为：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">groupId = org.apache.spark</span><br><span class="line">artifactId = spark-core_2.10</span><br><span class="line">version = 1.6.1</span><br></pre></td></tr></table></figure>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Guide、Manual和Tutorials的区别]]></title>
      <url>http://shengdeng.github.io/2016/05/06/Guide%E3%80%81Manual%E5%92%8CTutorial%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
      <content type="html"><![CDATA[<p>开源技术的官方网站提供了许多指导文档，理解他们的真正含义，会有事半功倍的效果。</p>
<a id="more"></a>
<h2 id="Tutorials"><a href="#Tutorials" class="headerlink" title="Tutorials"></a>Tutorials</h2><p>Tutorial </p>
<ul>
<li>n. 个别指导</li>
<li>对一个关键点的指导文档，一个Tutorial只教会一个关键点</li>
<li>例如，如果你在<a href="https://class.coursera.org/progfun-005/wiki/ScalaStyleGuide" title="scala公开课" target="_blank" rel="external">scala公开课</a>的wiki（实现团队协作编辑网页和文档共享的网站）上看到Eclipse tutorial，那么这个教程将教你如何在eclipse上开发scala项目，有时点到Hello World为止，仅此而已，不会介绍更多的eclipse使用方法。</li>
</ul>
<p>Tutorials</p>
<ul>
<li>Tutorial的复数形式，即众多的知识点教程的集合</li>
<li>例如，scala官网文档<a href="http://docs.scala-lang.org/tutorials/?_ga=1.81127127.178612781.1460424230" target="_blank" rel="external">Scala Tutorials</a>的目录，罗列了许多scala的关键知识点的指导教程，不像Guide会分章节。</li>
</ul>
<p>所以，Tutorials文档有点对系统中各个知识点逐个击破的意味。</p>
<h2 id="Guide"><a href="#Guide" class="headerlink" title="Guide"></a>Guide</h2><p>Guide</p>
<ul>
<li>n. 指南；向导；入门书</li>
<li>指导作用且对技术的理解有帮助的文档，可以理解为国内常用的“从入门道精通”，通常先解释技术原理，然后指导使用方法，适合学习</li>
</ul>
<p>官网的Guide是很重要的学习资料，随软件或语言版本及时更新，也是最权威的指南！英语不好的同学可以google Guide的中文翻译，比如，找“Spark Programming Guide”中文翻译，可以搜 “Spark” “编程指南”，但是一定要注意翻译对应的版本是否和你的软件版本一致。</p>
<h2 id="Manual"><a href="#Manual" class="headerlink" title="Manual"></a>Manual</h2><p>Manual</p>
<ul>
<li>n. 使用手册</li>
<li>工作时放在手边随时查阅的文档，内容全面，语言精炼高效，适合忘记某个参数时快速查阅使用方法</li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[自品牌也应该有的信念：如果不能成为第一，一开始就不要碰]]></title>
      <url>http://shengdeng.github.io/2016/05/04/%E8%87%AA%E5%93%81%E7%89%8C%E4%B9%9F%E5%BA%94%E8%AF%A5%E6%9C%89%E7%9A%84%E4%BF%A1%E5%BF%B5%EF%BC%9A%E5%A6%82%E6%9E%9C%E4%B8%8D%E8%83%BD%E6%88%90%E4%B8%BA%E7%AC%AC%E4%B8%80%EF%BC%8C%E4%B8%80%E5%BC%80%E5%A7%8B%E5%B0%B1%E4%B8%8D%E8%A6%81%E7%A2%B0/</url>
      <content type="html"><![CDATA[<p><strong>读书笔记：《记事本圆梦计划》PART 7</strong></p>
<blockquote>
<p>实习以后，最大的感触的就是职业生涯已经开始了，本来回学校想好好再享受一把，却十分不安，不想像本科的时候一样，因为要接触社会而感到焦虑不堪。或许，最近书看多了，把脑袋里的小怪兽调教的不安分，总吵吵着要干这个、学学那个。这篇读书笔记就是在小怪兽的吵吵下写的，之后搭建好了个人博客，再写计划、任务入嘀嗒收集箱，终于，有了滑板鞋 天黑都不怕 一步两步 一步两步…摩擦 摩擦 我给自己打着 节拍…</p>
</blockquote>
<p>最近想要建立自品牌形象，想着要经营微博，facebook，公众号，想着搭建个人主页博客，写技术博客，一边摸索一边又觉得毫无头绪，处在工作起步阶段的我还要不断学习新专业技能，同时又经营社交网络，会不会力不从心得不偿失？要发布哪些东西到社交网站？技术博客要有什么主题内容？才能吸引人，我的自品牌要建立怎样的形象？自品牌对我的人生有什么影响？还有很多要思考的问题。小确信，《记事本》中的内容给了我一丢丢的启发。</p>
<a id="more"></a>
<p><strong>正文</strong></p>
<p>PART 7中熊谷作为企业家，介绍了他管理公司的一些基本但很重要的观点。从这些观点中得到了一些启发，产生了一点联想，让我对自己将要建立的自品牌有了一个初步的想法。</p>
<h3 id="传递梦想：让一切建立在感动之上"><a href="#传递梦想：让一切建立在感动之上" class="headerlink" title="传递梦想：让一切建立在感动之上"></a>传递梦想：让一切建立在感动之上</h3><blockquote>
<p>经营公司最大的目的不是追求盈利，而是让经营者的梦想及感动，与<strong>员工、顾客、股东、合作厂商等人</strong>共同分享。</p>
</blockquote>
<p>熊谷用反证解释了这句话，如果老板不与任何人分享感动或者梦想，一味以营收来经营事业的话：</p>
<ul>
<li>员工：为钱工作→更高的薪水→跳槽</li>
<li>顾客：看价格→买更便宜的</li>
<li>股东：看报表→不理想→撤资</li>
</ul>
<p>如此的残酷都是因为只看眼前利益。所以说，要让与你的事业有利害关系的角色，与你有一致的梦想，甚至能创造出“笑容”和“感动”的想法，与你一起实现梦想（经营事业），那么他们不会残酷地离开你，因为<strong>你们之间获得了金钱无法换来的感动</strong>，同样也能带动营销与获利。</p>
<p>读完书里的这节内容，很容易联想到一些出色的大公司，当你听到他的品牌名字的时候，脑海里马上浮现他们的CEO阐述梦想的画面，和那些实践梦想的优秀产品，而且你一定会为这些与你认同的梦想买单。</p>
<p>同样的，在自品牌这个话题上，想一个场景，没有传递梦想与感动的博客是怎样的</p>
<ul>
<li>没有梦想和原则→自己写的文章说的话都打脸→不可靠称不上品牌</li>
<li>偶尔好文，博文内容良莠不齐→读者看一次而已→不会长久关注</li>
<li>读者的评论不回复，觉得浪费时间→读者觉得是一个“死”的博客→无法获得感动→无法建立联系</li>
</ul>
<p>好的博客是有灵魂的，可以互动的，读者阅读一篇文章之后会去读其他文章，会去好奇作者是什么人，会去找这个博主的联系方式。更厉害的是，在谈论某个领域时，读者可以马上想到你；又或他觉得你的博客值得分享给更多的人。这些都是因为博主在传递信息的同时，让读者感动。</p>
<p>因此，让自品牌能够传递梦想与感动也很重要。<strong>让“读者”能够感同你的梦想，并且从你做的事中得到感动，最后你将从别人那里收获感动</strong>。接下来就是要想清楚，<strong>我有什么样的梦想，在这个梦想下做出什么事能让大家感动</strong>。从小处可以做的，写一篇技术教程博客，能够把技术细节，把坑都解释透彻，能让读者觉得收获很大；博客的文章不是随意的，保证不要误导和出现错误，表达简洁清晰，这些也许就能传递一点点感动；回复读者的评论，和读者成为网络社交的好友，在专业领域和读者互动，也让读者来创造“笑容”和“感动”的想法。请想清楚，有哪些需要做到的细节。</p>
<h3 id="彻底到细节的执行力"><a href="#彻底到细节的执行力" class="headerlink" title="彻底到细节的执行力"></a>彻底到细节的执行力</h3><p>说到细节，熊谷对细节的要求已经到了极致的程度，他规定，桌椅在地板上有记号，若是移动了可以马上归位，甚至要求厕所一定要保持整洁，维持洗手台的干爽。他的观点是</p>
<blockquote>
<p>力量存在于细节中。对于小事不随便的公司，才能抓住厂商或是客人的心。</p>
</blockquote>
<p>如此<strong>彻底到细节的执行力</strong>，可以给人留下印象：</p>
<ul>
<li>清爽整洁，业务效率一定会很高</li>
<li>可靠，不允许出现差错</li>
</ul>
<p>打造自品牌的时候亦需要彻底的执行力，品牌创建初期，大家不了解你的时候，如果一个不注意的细节给别人造成先入为主的差印象就很麻烦了。那要如何培养彻底的执行力：</p>
<ol>
<li>首先，制定基本的行为规范：    <ul>
<li><strong>事无巨细的行为规范</strong>。可以让我们对每件事都有迅速的判断力（价值观），不会把时间浪费在纠结上；终极的效果是，让人感觉到发布的东西有统一的灵魂，能感觉是出自某一个人之手。</li>
<li><strong>有个性的行为规范</strong>。幽默？睿智？当灵魂有了个性，就增加了识别度，人们可以从茫茫人海中把你找出来。就像好声音评委说的：你的声音很有特色，我喜欢，加入我的战队吧。</li>
</ul>
</li>
<li>执行！执行！执行！<ul>
<li>《记事本圆梦计划》这本书，就是教你如何让梦想落地，将计划具体化数字化然后执行。《番茄工作法图解》、《小强升职记》等时间管理类的书都会教你如何高效的执行。看完书后，在执行过程中产生了一些新的想法，今后补上读书笔记。</li>
</ul>
</li>
</ol>
<h3 id="不战而胜：独一无二的优质"><a href="#不战而胜：独一无二的优质" class="headerlink" title="不战而胜：独一无二的优质"></a>不战而胜：独一无二的优质</h3><blockquote>
<p>熊谷的“三项求胜方针”：  </p>
<ol>
<li>不能成为第一名的事情，从一开始就不去碰  </li>
<li>不战而胜  </li>
<li>养成求胜的习惯</li>
</ol>
</blockquote>
<p>第一项，不可能成为第一的情况下，勉强展开事业也不太可能获得胜利，就是有把握成为第一的情况下才行动。在他看来只有一项达成了，才能拿下第二项，即在竞争中<strong>不战而胜</strong>。用下面两个场景来解释：</p>
<ul>
<li>在不可能成为第一的领域：<ul>
<li>双方实力相当→价格战（不正当竞争）→恶性循环→员工每天“面对残酷竞争”的心境而感到不幸</li>
</ul>
</li>
<li>在可能成为第一的领域：<ul>
<li>具有压倒性的第一→不参与不正当竞争→以稍高的价格提供优质的服务→员工可以有足够多的收益</li>
</ul>
</li>
</ul>
<p>那么问题来了，怎样才有可能成为领域第一呢？熊谷建议</p>
<blockquote>
<p>我为了要得到这样一个“不战而胜”的理想国，而比谁都要早去开发新事业，也就是“最先到达埋藏着宝藏的无人岛”，就算同业竞争的人增多，我也会朝“与别人相比能够得到压倒性领先”的方向去努力。</p>
</blockquote>
<p>最近一本书《从0到1》很火，书中对“寻找无人岛”提供了更加丰富的方法论。各种性格爱好经历背景排列组合的你一定是与众不同的，你有的别人没有的就是所谓的“无人岛”，所以我觉得自品牌的创建就是挖掘自身非凡的特质，产出独一无二的优质内容，这样才能让受众对你的自品牌产生巨大的兴趣，甚至产生依赖。永远坚持原创，永远不做同质化的东西，宁缺毋滥。没错，很难，但方向是对的，不是吗？唯有多读书，多阅历，慢慢摸索。</p>
<hr>
<h3 id="自媒体和自品牌有什么区别"><a href="#自媒体和自品牌有什么区别" class="headerlink" title="自媒体和自品牌有什么区别"></a>自媒体和自品牌有什么区别</h3><p>自媒体很火现在，本来写了一段自媒体和自品牌的区别，后来又删了，觉得没有必要咬文嚼字，硬要说出区别，那就一点：自媒体与职业生涯可能有关可能无关，也许只是为了社交、好玩；自品牌一定是与职业生涯有关，伴随一生，需要精心维护的。这带来的另一个好处就是，你的职业生涯被记录了，不仅可以约束一个人的言论，也可以帮助你朝着更正能量的方向发展（因为欣赏你的人一定与你持有相同的价值观，越多的人欣赏你，你的价值观就越主流，这并不是说主流价值观就是好的，但大多数情况下，主流价值观给人的感受就是正能量满满；当然，你也可以持有一些非主流，只要做的好，也会成为小众信赖的品牌）。</p>
]]></content>
    </entry>
    
  
  
</search>
